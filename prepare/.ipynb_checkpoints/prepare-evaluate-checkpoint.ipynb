{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5c8385c",
   "metadata": {},
   "source": [
    "# Evalute result with non-paperaware\n",
    "- We will evauluate pretrained weight `MobileNetV3-Large-2021-05-26-01-37-33-epoch0071-train_loss1.831597-val_loss1.799177-val_acc0.589499.zip` with previous (non-paperaware) model.\n",
    "- Evauluation date: 2021/06/03\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb2373a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_WEIGHT_PATH = '/media/jungin500/windows-10/Workspace/study-projects/ipcvl2021-mobilenetv3-torch-v2/prepare/.checkpoints' + \\\n",
    "    '/MobileNetV3-Large-2021-05-26-01-37-33-epoch0071-train_loss1.831597-val_loss1.799177-val_acc0.589499.zip'\n",
    "    \n",
    "import os\n",
    "if not os.path.isfile(EVAL_WEIGHT_PATH):\n",
    "    print(\"Weight file not found! specify correct directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80a37a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch import from_numpy\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "from xml.etree import ElementTree\n",
    "\n",
    "import numpy as np\n",
    "import torchsummary\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fa0c6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    ImageNet Label Reader (only for ImageNet datsets!)\n",
    "'''\n",
    "class LabelReader(object):\n",
    "    def __init__(self, label_file_path):\n",
    "        self.label_file_path = label_file_path\n",
    "        if 'pretrained' in label_file_path:\n",
    "            print(\"INFO: Using Pretrained label list! (not custom one)\")\n",
    "\n",
    "    def load_label(self):\n",
    "        label_map = {}\n",
    "        # Read label file into label map\n",
    "        if os.path.isfile(self.label_file_path):\n",
    "            with open(self.label_file_path, 'r') as f:\n",
    "                label_name_body = f.read().strip()\n",
    "                label_name_lines = label_name_body.split(\"\\n\")\n",
    "                for label_entry in tqdm(label_name_lines, desc='레이블 파일 읽기 작업'):\n",
    "                    synset_name, label_name = label_entry.strip().split(\"|\")\n",
    "                    label_map[synset_name] = label_name\n",
    "\n",
    "            print(f\"레이블 파일 읽기 완료: 총 {len(list(label_map.keys()))}개 레이블 검색\")\n",
    "            return label_map\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7835420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_BASE_DIR = \".\" + os.sep + \".cache\"\n",
    "IMG_PATH_LIST_PKL_FILENAME = CACHE_BASE_DIR + os.sep + 'img_path_list'\n",
    "IMG_CLASS_LIST_PKL_FILENAME = CACHE_BASE_DIR + os.sep + 'img_class_list'\n",
    "\n",
    "'''\n",
    "    ImageNet Dataset (we can get labels from `LabelReader(path).load_label()`!\n",
    "'''\n",
    "class ImageNet(torch.utils.data.Dataset):\n",
    "    def __init__(self, labels, root_dir, transform=None):\n",
    "        super(ImageNet, self).__init__()\n",
    "\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "        self.img_path_list = []\n",
    "        self.img_class_list = []\n",
    "        self.load_list(root_dir)\n",
    "\n",
    "    def load_list(self, root_dir):\n",
    "        label_index = 0\n",
    "        for label in tqdm(self.labels.keys(), desc='이미지 파일 리스트 읽기 작업'):\n",
    "            item_dir = os.path.join(root_dir, label)\n",
    "            file_list = glob.glob(item_dir + os.sep + \"*.JPEG\")\n",
    "            self.img_path_list += file_list\n",
    "            self.img_class_list += [label_index] * len(file_list)\n",
    "            label_index += 1\n",
    "\n",
    "        if len(self.img_path_list) != len(self.img_class_list):\n",
    "            raise RuntimeError(f\"이미지 데이터 {len(self.img_path_list)}개와 클래스 데이터 {len(self.img_class_list)}개가 서로 다릅니다!\")\n",
    "\n",
    "        print(f\"총 {len(self.img_path_list)}개 이미지 리스트 데이터 및 실효 레이블 {len(list(set(self.img_class_list)))}개 로드 성공\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # PIL-version\n",
    "        image = Image.open(self.img_path_list[idx]).convert(\"RGB\")\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        label = torch.Tensor([self.img_class_list[idx]]).type(torch.int64).squeeze(dim=0)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fffc20dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    VOC Dataset (without label! root_dir automatically scans for label list)\n",
    "'''\n",
    "class VOC(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        super(VOC, self).__init__()\n",
    "        self.transform = transform\n",
    "\n",
    "        self.img_path_list = []\n",
    "        self.img_class_list = []\n",
    "        self.labels = []\n",
    "\n",
    "        if os.path.isfile('dataset.pkl'):\n",
    "            print(\"Loading annotations from cache\")\n",
    "            self.img_path_list, self.img_class_list, self.labels = pickle.load(open('dataset.pkl', 'rb'))\n",
    "        else:\n",
    "            self.load_list(root_dir)\n",
    "            print(\"Saved annotations to  cache\")\n",
    "\n",
    "        self.img_class_list = from_numpy(self.img_class_list)\n",
    "\n",
    "    def load_list(self, root_dir):\n",
    "        annotation_dir = os.path.join(root_dir, 'Annotations')\n",
    "        images_dir = os.path.join(root_dir, 'JPEGImages')\n",
    "\n",
    "        label_map = {}\n",
    "        for xml_filename in tqdm(glob.glob(os.path.join(annotation_dir, '*.xml')), desc='클래스 리스트 생성 작업'):\n",
    "            with open(xml_filename, 'r') as f:\n",
    "                xml_body = f.read()\n",
    "                root = ElementTree.fromstring(xml_body)\n",
    "                for item in root.findall('object'):\n",
    "                    label_map[item.find('name').text] = True\n",
    "        self.labels = list(sorted(label_map.keys()))\n",
    "\n",
    "        for xml_filename in tqdm(glob.glob(os.path.join(annotation_dir, '*.xml')), desc='이미지 어노테이션 읽기 작업'):\n",
    "            with open(xml_filename, 'r') as f:\n",
    "                xml_body = f.read()\n",
    "                root = ElementTree.fromstring(xml_body)\n",
    "                image_file_path = os.path.join(images_dir, root.find('filename').text)\n",
    "                for item in root.findall('object'):\n",
    "                    label_index = self.labels.index(item.find('name').text)\n",
    "                    assert label_index != -1\n",
    "\n",
    "                    self.img_path_list.append(image_file_path)\n",
    "                    self.img_class_list.append(label_index)\n",
    "\n",
    "        self.img_class_list = np.array(self.img_class_list, dtype=np.int64)\n",
    "        pickle.dump((self.img_path_list, self.img_class_list, self.labels), open('dataset.pkl', 'wb'))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.img_path_list[idx]).convert(\"RGB\")\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        label = self.img_class_list[idx]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c017ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    MobileNetV3-Large Model Structure consisted of:\n",
    "    - SqueezeExcite Module\n",
    "    - Bottleneck Module\n",
    "'''\n",
    "class SqueezeExciteModule(nn.Module):\n",
    "    def __init__(self, expand_size):\n",
    "        super(SqueezeExciteModule, self).__init__()\n",
    "\n",
    "        self.se_0_0 = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        self.se_0_1 = nn.Flatten()\n",
    "\n",
    "        self.se_1_0 = nn.Linear(in_features=expand_size, out_features=expand_size)\n",
    "        self.se_1_1 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.se_2_0 = nn.Linear(in_features=expand_size, out_features=expand_size)\n",
    "        self.se_2_1 = nn.Hardsigmoid(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.se_0_0(x)\n",
    "        x = self.se_0_1(x)\n",
    "\n",
    "        x = self.se_1_0(x)\n",
    "        x = self.se_1_1(x)\n",
    "\n",
    "        x = self.se_2_0(x)\n",
    "        x = self.se_2_1(x)\n",
    "        x = torch.unsqueeze(x, -1)\n",
    "        x = torch.unsqueeze(x, -1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dw_kernel_size, expand_size, squeeze_excite,\n",
    "                 nonlinearity, stride):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.expand_size = expand_size\n",
    "        self.squeeze_excite = squeeze_excite\n",
    "        self.stride = stride\n",
    "        self.dw_kernel_size = dw_kernel_size\n",
    "\n",
    "        if nonlinearity == 'hardswish':\n",
    "            self.Nonliearity = nn.Hardswish\n",
    "        elif nonlinearity == 'relu':\n",
    "            self.Nonliearity = nn.ReLU\n",
    "        else:\n",
    "            raise RuntimeError(\"No such nonlinearity!\")\n",
    "\n",
    "        # 1x1 Conv2d + NL\n",
    "        self.bottleneck_0_0 = nn.Conv2d(in_channels=in_channels, out_channels=expand_size, kernel_size=(1, 1),\n",
    "                                        bias=False)\n",
    "        self.bottleneck_0_1 = nn.BatchNorm2d(num_features=expand_size)\n",
    "        self.bottleneck_0_2 = self.Nonliearity(inplace=True)\n",
    "\n",
    "        # Dwise + NL\n",
    "        self.bottleneck_1_0 = nn.Conv2d(in_channels=expand_size, out_channels=expand_size,\n",
    "                                        kernel_size=self.dw_kernel_size,\n",
    "                                        stride=self.stride, padding=self.dw_kernel_size[0] // 2, groups=expand_size,\n",
    "                                        bias=False)\n",
    "        self.bottleneck_1_1 = nn.BatchNorm2d(num_features=expand_size)\n",
    "\n",
    "        # Squeeze-Excite\n",
    "        if self.squeeze_excite:\n",
    "            self.squeeze_excite_0 = SqueezeExciteModule(\n",
    "                expand_size=expand_size\n",
    "            )\n",
    "        else:\n",
    "            self.squeeze_excite_0 = nn.Identity()\n",
    "\n",
    "        # Final 1x1 Conv2d\n",
    "        self.bottleneck_final_0 = nn.Conv2d(in_channels=expand_size, out_channels=out_channels, kernel_size=(1, 1),\n",
    "                                            bias=False)\n",
    "        self.bottleneck_final_1 = nn.BatchNorm2d(num_features=out_channels)\n",
    "\n",
    "        # Downsampling first layer\n",
    "        self.bottleneck_final_2 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                                            kernel_size=(1, 1), stride=self.stride, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_0 = self.bottleneck_0_0(x)\n",
    "        x_0 = self.bottleneck_0_1(x_0)\n",
    "        x_0 = self.bottleneck_0_2(x_0)\n",
    "\n",
    "        x_0 = self.bottleneck_1_0(x_0)\n",
    "        x_0 = self.bottleneck_1_1(x_0)\n",
    "\n",
    "        x_1 = self.squeeze_excite_0(x_0)\n",
    "        x_0 = x_0 * x_1\n",
    "\n",
    "        x_0 = self.bottleneck_final_0(x_0)\n",
    "        x_0 = self.bottleneck_final_1(x_0)\n",
    "        x_b = self.bottleneck_final_2(x)\n",
    "        return x_0.add(x_b)\n",
    "\n",
    "\n",
    "class MobileNetV3(nn.Module):\n",
    "    def __init__(self, width_mult=1.0, classifier=True, classifier_out_features=1000):\n",
    "        super(MobileNetV3, self).__init__()\n",
    "\n",
    "        conv_0_0 = nn.Conv2d(in_channels=3, out_channels=int(16 * width_mult),\n",
    "                             kernel_size=(3, 3), stride=2, padding=3 // 2, bias=False)\n",
    "        conv_0_1 = nn.BatchNorm2d(num_features=int(16 * width_mult))\n",
    "        conv_0_2 = nn.Hardswish(inplace=True)\n",
    "\n",
    "        conv_1_0 = Bottleneck(in_channels=int(16 * width_mult),\n",
    "                              out_channels=int(16 * width_mult), dw_kernel_size=(3, 3),\n",
    "                              expand_size=16, squeeze_excite=True, nonlinearity='relu', stride=2)\n",
    "        conv_2_0 = Bottleneck(in_channels=int(16 * width_mult),\n",
    "                              out_channels=int(24 * width_mult), dw_kernel_size=(3, 3),\n",
    "                              expand_size=72, squeeze_excite=False, nonlinearity='relu', stride=2)\n",
    "        conv_3_0 = Bottleneck(in_channels=int(24 * width_mult),\n",
    "                              out_channels=int(24 * width_mult), dw_kernel_size=(3, 3),\n",
    "                              expand_size=88, squeeze_excite=False, nonlinearity='relu', stride=1)\n",
    "        conv_4_0 = Bottleneck(in_channels=int(24 * width_mult),\n",
    "                              out_channels=int(40 * width_mult), dw_kernel_size=(5, 5),\n",
    "                              expand_size=96, squeeze_excite=True, nonlinearity='hardswish', stride=2)\n",
    "        conv_5_0 = Bottleneck(in_channels=int(40 * width_mult),\n",
    "                              out_channels=int(40 * width_mult), dw_kernel_size=(5, 5),\n",
    "                              expand_size=240, squeeze_excite=True, nonlinearity='hardswish', stride=1)\n",
    "        conv_6_0 = Bottleneck(in_channels=int(40 * width_mult),\n",
    "                              out_channels=int(40 * width_mult), dw_kernel_size=(5, 5),\n",
    "                              expand_size=240, squeeze_excite=True, nonlinearity='hardswish', stride=1)\n",
    "        conv_7_0 = Bottleneck(in_channels=int(40 * width_mult),\n",
    "                              out_channels=int(48 * width_mult), dw_kernel_size=(5, 5),\n",
    "                              expand_size=120, squeeze_excite=True, nonlinearity='hardswish', stride=1)\n",
    "        conv_8_0 = Bottleneck(in_channels=int(48 * width_mult),\n",
    "                              out_channels=int(48 * width_mult), dw_kernel_size=(5, 5),\n",
    "                              expand_size=144, squeeze_excite=True, nonlinearity='hardswish', stride=1)\n",
    "        conv_9_0 = Bottleneck(in_channels=int(48 * width_mult),\n",
    "                              out_channels=int(96 * width_mult), dw_kernel_size=(5, 5),\n",
    "                              expand_size=288, squeeze_excite=True, nonlinearity='hardswish', stride=2)\n",
    "        conv_10_0 = Bottleneck(in_channels=int(96 * width_mult),\n",
    "                               out_channels=int(96 * width_mult), dw_kernel_size=(5, 5),\n",
    "                               expand_size=576, squeeze_excite=True, nonlinearity='hardswish', stride=1)\n",
    "        conv_11_0 = Bottleneck(in_channels=int(96 * width_mult),\n",
    "                               out_channels=int(96 * width_mult), dw_kernel_size=(5, 5),\n",
    "                               expand_size=576, squeeze_excite=True, nonlinearity='hardswish', stride=1)\n",
    "\n",
    "        conv_12_0 = nn.Conv2d(in_channels=int(96 * width_mult), out_channels=int(576 * width_mult),\n",
    "                              kernel_size=(1, 1), bias=False)\n",
    "        conv_12_1 = nn.Hardswish(inplace=True)\n",
    "        conv_12_2 = nn.BatchNorm2d(num_features=int(576 * width_mult))\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            conv_0_0,\n",
    "            conv_0_1,\n",
    "            conv_0_2,\n",
    "            conv_1_0,\n",
    "            conv_2_0,\n",
    "            conv_3_0,\n",
    "            conv_4_0,\n",
    "            conv_5_0,\n",
    "            conv_6_0,\n",
    "            conv_7_0,\n",
    "            conv_8_0,\n",
    "            conv_9_0,\n",
    "            conv_10_0,\n",
    "            conv_11_0,\n",
    "            conv_12_0,\n",
    "            conv_12_1,\n",
    "            conv_12_2\n",
    "        )\n",
    "\n",
    "        if classifier:\n",
    "            self.classifiers = nn.Sequential(\n",
    "                nn.AdaptiveAvgPool2d(output_size=1),\n",
    "                nn.Flatten(start_dim=1),\n",
    "                nn.Linear(int(576 * width_mult), int(1024 * width_mult)),\n",
    "                nn.Dropout(p=0.2),\n",
    "                nn.Linear(int(1024 * width_mult), classifier_out_features)\n",
    "            )\n",
    "        else:\n",
    "            self.classifiers = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifiers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca88e0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 112, 112]             432\n",
      "       BatchNorm2d-2         [-1, 16, 112, 112]              32\n",
      "         Hardswish-3         [-1, 16, 112, 112]               0\n",
      "            Conv2d-4         [-1, 16, 112, 112]             256\n",
      "       BatchNorm2d-5         [-1, 16, 112, 112]              32\n",
      "              ReLU-6         [-1, 16, 112, 112]               0\n",
      "            Conv2d-7           [-1, 16, 56, 56]             144\n",
      "       BatchNorm2d-8           [-1, 16, 56, 56]              32\n",
      " AdaptiveAvgPool2d-9             [-1, 16, 1, 1]               0\n",
      "          Flatten-10                   [-1, 16]               0\n",
      "           Linear-11                   [-1, 16]             272\n",
      "             ReLU-12                   [-1, 16]               0\n",
      "           Linear-13                   [-1, 16]             272\n",
      "      Hardsigmoid-14                   [-1, 16]               0\n",
      "SqueezeExciteModule-15             [-1, 16, 1, 1]               0\n",
      "           Conv2d-16           [-1, 16, 56, 56]             256\n",
      "      BatchNorm2d-17           [-1, 16, 56, 56]              32\n",
      "           Conv2d-18           [-1, 16, 56, 56]             256\n",
      "       Bottleneck-19           [-1, 16, 56, 56]               0\n",
      "           Conv2d-20           [-1, 72, 56, 56]           1,152\n",
      "      BatchNorm2d-21           [-1, 72, 56, 56]             144\n",
      "             ReLU-22           [-1, 72, 56, 56]               0\n",
      "           Conv2d-23           [-1, 72, 28, 28]             648\n",
      "      BatchNorm2d-24           [-1, 72, 28, 28]             144\n",
      "         Identity-25           [-1, 72, 28, 28]               0\n",
      "           Conv2d-26           [-1, 24, 28, 28]           1,728\n",
      "      BatchNorm2d-27           [-1, 24, 28, 28]              48\n",
      "           Conv2d-28           [-1, 24, 28, 28]             384\n",
      "       Bottleneck-29           [-1, 24, 28, 28]               0\n",
      "           Conv2d-30           [-1, 88, 28, 28]           2,112\n",
      "      BatchNorm2d-31           [-1, 88, 28, 28]             176\n",
      "             ReLU-32           [-1, 88, 28, 28]               0\n",
      "           Conv2d-33           [-1, 88, 28, 28]             792\n",
      "      BatchNorm2d-34           [-1, 88, 28, 28]             176\n",
      "         Identity-35           [-1, 88, 28, 28]               0\n",
      "           Conv2d-36           [-1, 24, 28, 28]           2,112\n",
      "      BatchNorm2d-37           [-1, 24, 28, 28]              48\n",
      "           Conv2d-38           [-1, 24, 28, 28]             576\n",
      "       Bottleneck-39           [-1, 24, 28, 28]               0\n",
      "           Conv2d-40           [-1, 96, 28, 28]           2,304\n",
      "      BatchNorm2d-41           [-1, 96, 28, 28]             192\n",
      "        Hardswish-42           [-1, 96, 28, 28]               0\n",
      "           Conv2d-43           [-1, 96, 14, 14]           2,400\n",
      "      BatchNorm2d-44           [-1, 96, 14, 14]             192\n",
      "AdaptiveAvgPool2d-45             [-1, 96, 1, 1]               0\n",
      "          Flatten-46                   [-1, 96]               0\n",
      "           Linear-47                   [-1, 96]           9,312\n",
      "             ReLU-48                   [-1, 96]               0\n",
      "           Linear-49                   [-1, 96]           9,312\n",
      "      Hardsigmoid-50                   [-1, 96]               0\n",
      "SqueezeExciteModule-51             [-1, 96, 1, 1]               0\n",
      "           Conv2d-52           [-1, 40, 14, 14]           3,840\n",
      "      BatchNorm2d-53           [-1, 40, 14, 14]              80\n",
      "           Conv2d-54           [-1, 40, 14, 14]             960\n",
      "       Bottleneck-55           [-1, 40, 14, 14]               0\n",
      "           Conv2d-56          [-1, 240, 14, 14]           9,600\n",
      "      BatchNorm2d-57          [-1, 240, 14, 14]             480\n",
      "        Hardswish-58          [-1, 240, 14, 14]               0\n",
      "           Conv2d-59          [-1, 240, 14, 14]           6,000\n",
      "      BatchNorm2d-60          [-1, 240, 14, 14]             480\n",
      "AdaptiveAvgPool2d-61            [-1, 240, 1, 1]               0\n",
      "          Flatten-62                  [-1, 240]               0\n",
      "           Linear-63                  [-1, 240]          57,840\n",
      "             ReLU-64                  [-1, 240]               0\n",
      "           Linear-65                  [-1, 240]          57,840\n",
      "      Hardsigmoid-66                  [-1, 240]               0\n",
      "SqueezeExciteModule-67            [-1, 240, 1, 1]               0\n",
      "           Conv2d-68           [-1, 40, 14, 14]           9,600\n",
      "      BatchNorm2d-69           [-1, 40, 14, 14]              80\n",
      "           Conv2d-70           [-1, 40, 14, 14]           1,600\n",
      "       Bottleneck-71           [-1, 40, 14, 14]               0\n",
      "           Conv2d-72          [-1, 240, 14, 14]           9,600\n",
      "      BatchNorm2d-73          [-1, 240, 14, 14]             480\n",
      "        Hardswish-74          [-1, 240, 14, 14]               0\n",
      "           Conv2d-75          [-1, 240, 14, 14]           6,000\n",
      "      BatchNorm2d-76          [-1, 240, 14, 14]             480\n",
      "AdaptiveAvgPool2d-77            [-1, 240, 1, 1]               0\n",
      "          Flatten-78                  [-1, 240]               0\n",
      "           Linear-79                  [-1, 240]          57,840\n",
      "             ReLU-80                  [-1, 240]               0\n",
      "           Linear-81                  [-1, 240]          57,840\n",
      "      Hardsigmoid-82                  [-1, 240]               0\n",
      "SqueezeExciteModule-83            [-1, 240, 1, 1]               0\n",
      "           Conv2d-84           [-1, 40, 14, 14]           9,600\n",
      "      BatchNorm2d-85           [-1, 40, 14, 14]              80\n",
      "           Conv2d-86           [-1, 40, 14, 14]           1,600\n",
      "       Bottleneck-87           [-1, 40, 14, 14]               0\n",
      "           Conv2d-88          [-1, 120, 14, 14]           4,800\n",
      "      BatchNorm2d-89          [-1, 120, 14, 14]             240\n",
      "        Hardswish-90          [-1, 120, 14, 14]               0\n",
      "           Conv2d-91          [-1, 120, 14, 14]           3,000\n",
      "      BatchNorm2d-92          [-1, 120, 14, 14]             240\n",
      "AdaptiveAvgPool2d-93            [-1, 120, 1, 1]               0\n",
      "          Flatten-94                  [-1, 120]               0\n",
      "           Linear-95                  [-1, 120]          14,520\n",
      "             ReLU-96                  [-1, 120]               0\n",
      "           Linear-97                  [-1, 120]          14,520\n",
      "      Hardsigmoid-98                  [-1, 120]               0\n",
      "SqueezeExciteModule-99            [-1, 120, 1, 1]               0\n",
      "          Conv2d-100           [-1, 48, 14, 14]           5,760\n",
      "     BatchNorm2d-101           [-1, 48, 14, 14]              96\n",
      "          Conv2d-102           [-1, 48, 14, 14]           1,920\n",
      "      Bottleneck-103           [-1, 48, 14, 14]               0\n",
      "          Conv2d-104          [-1, 144, 14, 14]           6,912\n",
      "     BatchNorm2d-105          [-1, 144, 14, 14]             288\n",
      "       Hardswish-106          [-1, 144, 14, 14]               0\n",
      "          Conv2d-107          [-1, 144, 14, 14]           3,600\n",
      "     BatchNorm2d-108          [-1, 144, 14, 14]             288\n",
      "AdaptiveAvgPool2d-109            [-1, 144, 1, 1]               0\n",
      "         Flatten-110                  [-1, 144]               0\n",
      "          Linear-111                  [-1, 144]          20,880\n",
      "            ReLU-112                  [-1, 144]               0\n",
      "          Linear-113                  [-1, 144]          20,880\n",
      "     Hardsigmoid-114                  [-1, 144]               0\n",
      "SqueezeExciteModule-115            [-1, 144, 1, 1]               0\n",
      "          Conv2d-116           [-1, 48, 14, 14]           6,912\n",
      "     BatchNorm2d-117           [-1, 48, 14, 14]              96\n",
      "          Conv2d-118           [-1, 48, 14, 14]           2,304\n",
      "      Bottleneck-119           [-1, 48, 14, 14]               0\n",
      "          Conv2d-120          [-1, 288, 14, 14]          13,824\n",
      "     BatchNorm2d-121          [-1, 288, 14, 14]             576\n",
      "       Hardswish-122          [-1, 288, 14, 14]               0\n",
      "          Conv2d-123            [-1, 288, 7, 7]           7,200\n",
      "     BatchNorm2d-124            [-1, 288, 7, 7]             576\n",
      "AdaptiveAvgPool2d-125            [-1, 288, 1, 1]               0\n",
      "         Flatten-126                  [-1, 288]               0\n",
      "          Linear-127                  [-1, 288]          83,232\n",
      "            ReLU-128                  [-1, 288]               0\n",
      "          Linear-129                  [-1, 288]          83,232\n",
      "     Hardsigmoid-130                  [-1, 288]               0\n",
      "SqueezeExciteModule-131            [-1, 288, 1, 1]               0\n",
      "          Conv2d-132             [-1, 96, 7, 7]          27,648\n",
      "     BatchNorm2d-133             [-1, 96, 7, 7]             192\n",
      "          Conv2d-134             [-1, 96, 7, 7]           4,608\n",
      "      Bottleneck-135             [-1, 96, 7, 7]               0\n",
      "          Conv2d-136            [-1, 576, 7, 7]          55,296\n",
      "     BatchNorm2d-137            [-1, 576, 7, 7]           1,152\n",
      "       Hardswish-138            [-1, 576, 7, 7]               0\n",
      "          Conv2d-139            [-1, 576, 7, 7]          14,400\n",
      "     BatchNorm2d-140            [-1, 576, 7, 7]           1,152\n",
      "AdaptiveAvgPool2d-141            [-1, 576, 1, 1]               0\n",
      "         Flatten-142                  [-1, 576]               0\n",
      "          Linear-143                  [-1, 576]         332,352\n",
      "            ReLU-144                  [-1, 576]               0\n",
      "          Linear-145                  [-1, 576]         332,352\n",
      "     Hardsigmoid-146                  [-1, 576]               0\n",
      "SqueezeExciteModule-147            [-1, 576, 1, 1]               0\n",
      "          Conv2d-148             [-1, 96, 7, 7]          55,296\n",
      "     BatchNorm2d-149             [-1, 96, 7, 7]             192\n",
      "          Conv2d-150             [-1, 96, 7, 7]           9,216\n",
      "      Bottleneck-151             [-1, 96, 7, 7]               0\n",
      "          Conv2d-152            [-1, 576, 7, 7]          55,296\n",
      "     BatchNorm2d-153            [-1, 576, 7, 7]           1,152\n",
      "       Hardswish-154            [-1, 576, 7, 7]               0\n",
      "          Conv2d-155            [-1, 576, 7, 7]          14,400\n",
      "     BatchNorm2d-156            [-1, 576, 7, 7]           1,152\n",
      "AdaptiveAvgPool2d-157            [-1, 576, 1, 1]               0\n",
      "         Flatten-158                  [-1, 576]               0\n",
      "          Linear-159                  [-1, 576]         332,352\n",
      "            ReLU-160                  [-1, 576]               0\n",
      "          Linear-161                  [-1, 576]         332,352\n",
      "     Hardsigmoid-162                  [-1, 576]               0\n",
      "SqueezeExciteModule-163            [-1, 576, 1, 1]               0\n",
      "          Conv2d-164             [-1, 96, 7, 7]          55,296\n",
      "     BatchNorm2d-165             [-1, 96, 7, 7]             192\n",
      "          Conv2d-166             [-1, 96, 7, 7]           9,216\n",
      "      Bottleneck-167             [-1, 96, 7, 7]               0\n",
      "          Conv2d-168            [-1, 576, 7, 7]          55,296\n",
      "       Hardswish-169            [-1, 576, 7, 7]               0\n",
      "     BatchNorm2d-170            [-1, 576, 7, 7]           1,152\n",
      "AdaptiveAvgPool2d-171            [-1, 576, 1, 1]               0\n",
      "         Flatten-172                  [-1, 576]               0\n",
      "          Linear-173                 [-1, 1024]         590,848\n",
      "         Dropout-174                 [-1, 1024]               0\n",
      "          Linear-175                 [-1, 1000]       1,025,000\n",
      "================================================================\n",
      "Total params: 3,931,344\n",
      "Trainable params: 3,931,344\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 36.01\n",
      "Params size (MB): 15.00\n",
      "Estimated Total Size (MB): 51.58\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Library Configuration\n",
    "'''\n",
    "# CUDA-related stuffs\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "model = MobileNetV3(width_mult=1.0, classifier=True, classifier_out_features=1000).float().to(device)\n",
    "torchsummary.summary(model, input_size=(3, 224, 224), device=device.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8fb77f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "레이블 파일 읽기 작업: 100%|██████████| 1000/1000 [00:00<00:00, 2369663.28it/s]\n",
      "이미지 파일 리스트 읽기 작업:  43%|████▎     | 431/1000 [00:00<00:00, 4302.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블 파일 읽기 완료: 총 1000개 레이블 검색\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "이미지 파일 리스트 읽기 작업: 100%|██████████| 1000/1000 [00:00<00:00, 4334.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 50000개 이미지 리스트 데이터 및 실효 레이블 1000개 로드 성공\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MobileNetV3(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Hardswish()\n",
       "    (3): Bottleneck(\n",
       "      (bottleneck_0_0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bottleneck_0_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bottleneck_0_2): ReLU(inplace=True)\n",
       "      (bottleneck_1_0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
       "      (bottleneck_1_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (squeeze_excite_0): SqueezeExciteModule(\n",
       "        (se_0_0): AdaptiveAvgPool2d(output_size=1)\n",
       "        (se_0_1): Flatten(start_dim=1, end_dim=-1)\n",
       "        (se_1_0): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (se_1_1): ReLU(inplace=True)\n",
       "        (se_2_0): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (se_2_1): Hardsigmoid()\n",
       "      )\n",
       "      (bottleneck_final_0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bottleneck_final_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bottleneck_final_2): Conv2d(16, 16, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (bottleneck_0_0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bottleneck_0_1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bottleneck_0_2): ReLU(inplace=True)\n",
       "      (bottleneck_1_0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
       "      (bottleneck_1_1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (squeeze_excite_0): Identity()\n",
       "      (bottleneck_final_0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bottleneck_final_1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bottleneck_final_2): Conv2d(16, 24, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (bottleneck_0_0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bottleneck_0_1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bottleneck_0_2): ReLU(inplace=True)\n",
       "      (bottleneck_1_0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
       "      (bottleneck_1_1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (squeeze_excite_0): Identity()\n",
       "      (bottleneck_final_0): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bottleneck_final_1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bottleneck_final_2): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (bottleneck_0_0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bottleneck_0_1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bottleneck_0_2): Hardswish()\n",
       "      (bottleneck_1_0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
       "      (bottleneck_1_1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (squeeze_excite_0): SqueezeExciteModule(\n",
       "        (se_0_0): AdaptiveAvgPool2d(output_size=1)\n",
       "        (se_0_1): Flatten(start_dim=1, end_dim=-1)\n",
       "        (se_1_0): Linear(in_features=96, out_features=96, bias=True)\n",
       "        (se_1_1): ReLU(inplace=True)\n",
       "        (se_2_0): Linear(in_features=96, out_features=96, bias=True)\n",
       "        (se_2_1): Hardsigmoid()\n",
       "      )\n",
       "      (bottleneck_final_0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bottleneck_final_1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bottleneck_final_2): Conv2d(24, 40, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (bottleneck_0_0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bottleneck_0_1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bottleneck_0_2): Hardswish()\n",
       "      (bottleneck_1_0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "      (bottleneck_1_1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (squeeze_excite_0): SqueezeExciteModule(\n",
       "        (se_0_0): AdaptiveAvgPool2d(output_size=1)\n",
       "        (se_0_1): Flatten(start_dim=1, end_dim=-1)\n",
       "        (se_1_0): Linear(in_features=240, out_features=240, bias=True)\n",
       "        (se_1_1): ReLU(inplace=True)\n",
       "        (se_2_0): Linear(in_features=240, out_features=240, bias=True)\n",
       "        (se_2_1): Hardsigmoid()\n",
       "      )\n",
       "      (bottleneck_final_0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bottleneck_final_1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bottleneck_final_2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (bottleneck_0_0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bottleneck_0_1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bottleneck_0_2): Hardswish()\n",
       "      (bottleneck_1_0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "      (bottleneck_1_1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (squeeze_excite_0): SqueezeExciteModule(\n",
       "        (se_0_0): AdaptiveAvgPool2d(output_size=1)\n",
       "        (se_0_1): Flatten(start_dim=1, end_dim=-1)\n",
       "        (se_1_0): Linear(in_features=240, out_features=240, bias=True)\n",
       "        (se_1_1): ReLU(inplace=True)\n",
       "        (se_2_0): Linear(in_features=240, out_features=240, bias=True)\n",
       "        (se_2_1): Hardsigmoid()\n",
       "      )\n",
       "      (bottleneck_final_0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bottleneck_final_1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bottleneck_final_2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (bottleneck_0_0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bottleneck_0_1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bottleneck_0_2): Hardswish()\n",
       "      (bottleneck_1_0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "      (bottleneck_1_1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (squeeze_excite_0): SqueezeExciteModule(\n",
       "        (se_0_0): AdaptiveAvgPool2d(output_size=1)\n",
       "        (se_0_1): Flatten(start_dim=1, end_dim=-1)\n",
       "        (se_1_0): Linear(in_features=120, out_features=120, bias=True)\n",
       "        (se_1_1): ReLU(inplace=True)\n",
       "        (se_2_0): Linear(in_features=120, out_features=120, bias=True)\n",
       "        (se_2_1): Hardsigmoid()\n",
       "      )\n",
       "      (bottleneck_final_0): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bottleneck_final_1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bottleneck_final_2): Conv2d(40, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (bottleneck_0_0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bottleneck_0_1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bottleneck_0_2): Hardswish()\n",
       "      (bottleneck_1_0): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
       "      (bottleneck_1_1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (squeeze_excite_0): SqueezeExciteModule(\n",
       "        (se_0_0): AdaptiveAvgPool2d(output_size=1)\n",
       "        (se_0_1): Flatten(start_dim=1, end_dim=-1)\n",
       "        (se_1_0): Linear(in_features=144, out_features=144, bias=True)\n",
       "        (se_1_1): ReLU(inplace=True)\n",
       "        (se_2_0): Linear(in_features=144, out_features=144, bias=True)\n",
       "        (se_2_1): Hardsigmoid()\n",
       "      )\n",
       "      (bottleneck_final_0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bottleneck_final_1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bottleneck_final_2): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (bottleneck_0_0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bottleneck_0_1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bottleneck_0_2): Hardswish()\n",
       "      (bottleneck_1_0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
       "      (bottleneck_1_1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (squeeze_excite_0): SqueezeExciteModule(\n",
       "        (se_0_0): AdaptiveAvgPool2d(output_size=1)\n",
       "        (se_0_1): Flatten(start_dim=1, end_dim=-1)\n",
       "        (se_1_0): Linear(in_features=288, out_features=288, bias=True)\n",
       "        (se_1_1): ReLU(inplace=True)\n",
       "        (se_2_0): Linear(in_features=288, out_features=288, bias=True)\n",
       "        (se_2_1): Hardsigmoid()\n",
       "      )\n",
       "      (bottleneck_final_0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bottleneck_final_1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bottleneck_final_2): Conv2d(48, 96, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (bottleneck_0_0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bottleneck_0_1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bottleneck_0_2): Hardswish()\n",
       "      (bottleneck_1_0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "      (bottleneck_1_1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (squeeze_excite_0): SqueezeExciteModule(\n",
       "        (se_0_0): AdaptiveAvgPool2d(output_size=1)\n",
       "        (se_0_1): Flatten(start_dim=1, end_dim=-1)\n",
       "        (se_1_0): Linear(in_features=576, out_features=576, bias=True)\n",
       "        (se_1_1): ReLU(inplace=True)\n",
       "        (se_2_0): Linear(in_features=576, out_features=576, bias=True)\n",
       "        (se_2_1): Hardsigmoid()\n",
       "      )\n",
       "      (bottleneck_final_0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bottleneck_final_1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bottleneck_final_2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (bottleneck_0_0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bottleneck_0_1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bottleneck_0_2): Hardswish()\n",
       "      (bottleneck_1_0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "      (bottleneck_1_1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (squeeze_excite_0): SqueezeExciteModule(\n",
       "        (se_0_0): AdaptiveAvgPool2d(output_size=1)\n",
       "        (se_0_1): Flatten(start_dim=1, end_dim=-1)\n",
       "        (se_1_0): Linear(in_features=576, out_features=576, bias=True)\n",
       "        (se_1_1): ReLU(inplace=True)\n",
       "        (se_2_0): Linear(in_features=576, out_features=576, bias=True)\n",
       "        (se_2_1): Hardsigmoid()\n",
       "      )\n",
       "      (bottleneck_final_0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bottleneck_final_1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bottleneck_final_2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (14): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (15): Hardswish()\n",
       "    (16): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (classifiers): Sequential(\n",
       "    (0): AdaptiveAvgPool2d(output_size=1)\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Linear(in_features=576, out_features=1024, bias=True)\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "    (4): Linear(in_features=1024, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = LabelReader(label_file_path='imagenet_label.custom.list').load_label()\n",
    "datasets = ImageNet(\n",
    "    labels=labels,\n",
    "    root_dir='/media/jungin500/windows-10/Dataset/ILSVRC/Data/CLS-LOC/val-sub',\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "#         transforms.Normalize(\n",
    "#             mean=[0.4547857, 0.4349471, 0.40525291],\n",
    "#             std=[0.12003352, 0.12323549, 0.1392444]\n",
    "#         )\n",
    "    ])\n",
    ")\n",
    "\n",
    "valid_dataloader = torch.utils.data.DataLoader(datasets, batch_size=128, \n",
    "                                              shuffle=False, num_workers=16, pin_memory=True, drop_last=False)\n",
    "\n",
    "checkpoint = torch.load(EVAL_WEIGHT_PATH)\n",
    "c_epoch = checkpoint['epoch'] + 1\n",
    "c_model_state_dict = checkpoint['model_state_dict']\n",
    "c_optimizer_state_dict = checkpoint['optimizer_state_dict']\n",
    "c_loss = checkpoint['loss']\n",
    "\n",
    "model.load_state_dict(c_model_state_dict)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba3dcb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Image Batch 0390/0391] Accuracy: 0.57053, Top-5 Accuracy: 0.80101: 100%|█████████████████████████████████████████████████████| 391/391 [00:40<00:00,  9.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 0.57053, Top-5 Acc 0.80101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vl = tqdm(enumerate(valid_dataloader), total=len(valid_dataloader), ncols=160, desc='Spawning Workers')\n",
    "accuracies = []\n",
    "top5_accuracies = []\n",
    "model.train(False)\n",
    "for i, (image, label) in vl:\n",
    "    if device.type != label.device.type:\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "    output = model(image)\n",
    "    accuracy = torch.mean(torch.eq(torch.argmax(output, dim=1), label).int().float())\n",
    "    top5_accuracy = torch.mean(torch.any(torch.eq(label.unsqueeze(1).repeat(1, 5), torch.argsort(output, dim=1)[:, -5:]), dim=1).int().float())\n",
    "\n",
    "    accuracies.append(accuracy.item())\n",
    "    top5_accuracies.append(top5_accuracy.item())\n",
    "\n",
    "    vl.set_description(\"[Image Batch %04d/%04d] Accuracy: %03.5f, Top-5 Accuracy: %03.5f\" %\n",
    "                (i, len(valid_dataloader), np.mean(accuracies), np.mean(top5_accuracies)))\n",
    "\n",
    "val_acc_value = np.mean(accuracies)\n",
    "val_acc2_value = np.mean(top5_accuracies)\n",
    "\n",
    "print(\"Acc %03.5f, Top-5 Acc %03.5f\" % (val_acc_value, val_acc2_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b8d3fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MAdd]: Hardswish is not supported!\n",
      "[Flops]: Hardswish is not supported!\n",
      "[Memory]: Hardswish is not supported!\n",
      "[MAdd]: Hardswish is not supported!\n",
      "[Flops]: Hardswish is not supported!\n",
      "[Memory]: Hardswish is not supported!\n",
      "[MAdd]: Hardswish is not supported!\n",
      "[Flops]: Hardswish is not supported!\n",
      "[Memory]: Hardswish is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: Flatten is not supported!\n",
      "[Flops]: Flatten is not supported!\n",
      "[Memory]: Flatten is not supported!\n",
      "[MAdd]: Flatten is not supported!\n",
      "[Flops]: Flatten is not supported!\n",
      "[Memory]: Flatten is not supported!\n",
      "[MAdd]: Flatten is not supported!\n",
      "[Flops]: Flatten is not supported!\n",
      "[Memory]: Flatten is not supported!\n",
      "[MAdd]: Hardsigmoid is not supported!\n",
      "[Flops]: Hardsigmoid is not supported!\n",
      "[Memory]: Hardsigmoid is not supported!\n",
      "[MAdd]: Hardsigmoid is not supported!\n",
      "[Flops]: Hardsigmoid is not supported!\n",
      "[Memory]: Hardsigmoid is not supported!\n",
      "[MAdd]: Hardsigmoid is not supported!\n",
      "[Flops]: Hardsigmoid is not supported!\n",
      "[Memory]: Hardsigmoid is not supported!\n",
      "[MAdd]: Identity is not supported!\n",
      "[Flops]: Identity is not supported!\n",
      "[Memory]: Identity is not supported!\n",
      "[MAdd]: Identity is not supported!\n",
      "[Flops]: Identity is not supported!\n",
      "[Memory]: Identity is not supported!\n",
      "[MAdd]: Identity is not supported!\n",
      "[Flops]: Identity is not supported!\n",
      "[Memory]: Identity is not supported!\n",
      "[MAdd]: Identity is not supported!\n",
      "[Flops]: Identity is not supported!\n",
      "[Memory]: Identity is not supported!\n",
      "[MAdd]: Identity is not supported!\n",
      "[Flops]: Identity is not supported!\n",
      "[Memory]: Identity is not supported!\n",
      "[MAdd]: Identity is not supported!\n",
      "[Flops]: Identity is not supported!\n",
      "[Memory]: Identity is not supported!\n",
      "[MAdd]: Hardswish is not supported!\n",
      "[Flops]: Hardswish is not supported!\n",
      "[Memory]: Hardswish is not supported!\n",
      "[MAdd]: Hardswish is not supported!\n",
      "[Flops]: Hardswish is not supported!\n",
      "[Memory]: Hardswish is not supported!\n",
      "[MAdd]: Hardswish is not supported!\n",
      "[Flops]: Hardswish is not supported!\n",
      "[Memory]: Hardswish is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: Flatten is not supported!\n",
      "[Flops]: Flatten is not supported!\n",
      "[Memory]: Flatten is not supported!\n",
      "[MAdd]: Flatten is not supported!\n",
      "[Flops]: Flatten is not supported!\n",
      "[Memory]: Flatten is not supported!\n",
      "[MAdd]: Flatten is not supported!\n",
      "[Flops]: Flatten is not supported!\n",
      "[Memory]: Flatten is not supported!\n",
      "[MAdd]: Hardsigmoid is not supported!\n",
      "[Flops]: Hardsigmoid is not supported!\n",
      "[Memory]: Hardsigmoid is not supported!\n",
      "[MAdd]: Hardsigmoid is not supported!\n",
      "[Flops]: Hardsigmoid is not supported!\n",
      "[Memory]: Hardsigmoid is not supported!\n",
      "[MAdd]: Hardsigmoid is not supported!\n",
      "[Flops]: Hardsigmoid is not supported!\n",
      "[Memory]: Hardsigmoid is not supported!\n",
      "[MAdd]: Hardswish is not supported!\n",
      "[Flops]: Hardswish is not supported!\n",
      "[Memory]: Hardswish is not supported!\n",
      "[MAdd]: Hardswish is not supported!\n",
      "[Flops]: Hardswish is not supported!\n",
      "[Memory]: Hardswish is not supported!\n",
      "[MAdd]: Hardswish is not supported!\n",
      "[Flops]: Hardswish is not supported!\n",
      "[Memory]: Hardswish is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: Flatten is not supported!\n",
      "[Flops]: Flatten is not supported!\n",
      "[Memory]: Flatten is not supported!\n",
      "[MAdd]: Flatten is not supported!\n",
      "[Flops]: Flatten is not supported!\n",
      "[Memory]: Flatten is not supported!\n",
      "[MAdd]: Flatten is not supported!\n",
      "[Flops]: Flatten is not supported!\n",
      "[Memory]: Flatten is not supported!\n",
      "[MAdd]: Hardsigmoid is not supported!\n",
      "[Flops]: Hardsigmoid is not supported!\n",
      "[Memory]: Hardsigmoid is not supported!\n",
      "[MAdd]: Hardsigmoid is not supported!\n",
      "[Flops]: Hardsigmoid is not supported!\n",
      "[Memory]: Hardsigmoid is not supported!\n",
      "[MAdd]: Hardsigmoid is not supported!\n",
      "[Flops]: Hardsigmoid is not supported!\n",
      "[Memory]: Hardsigmoid is not supported!\n",
      "[MAdd]: Hardswish is not supported!\n",
      "[Flops]: Hardswish is not supported!\n",
      "[Memory]: Hardswish is not supported!\n",
      "[MAdd]: Hardswish is not supported!\n",
      "[Flops]: Hardswish is not supported!\n",
      "[Memory]: Hardswish is not supported!\n",
      "[MAdd]: Hardswish is not supported!\n",
      "[Flops]: Hardswish is not supported!\n",
      "[Memory]: Hardswish is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: Flatten is not supported!\n",
      "[Flops]: Flatten is not supported!\n",
      "[Memory]: Flatten is not supported!\n",
      "[MAdd]: Flatten is not supported!\n",
      "[Flops]: Flatten is not supported!\n",
      "[Memory]: Flatten is not supported!\n",
      "[MAdd]: Flatten is not supported!\n",
      "[Flops]: Flatten is not supported!\n",
      "[Memory]: Flatten is not supported!\n",
      "[MAdd]: Hardsigmoid is not supported!\n",
      "[Flops]: Hardsigmoid is not supported!\n",
      "[Memory]: Hardsigmoid is not supported!\n",
      "[MAdd]: Hardsigmoid is not supported!\n",
      "[Flops]: Hardsigmoid is not supported!\n",
      "[Memory]: Hardsigmoid is not supported!\n",
      "[MAdd]: Hardsigmoid is not supported!\n",
      "[Flops]: Hardsigmoid is not supported!\n",
      "[Memory]: Hardsigmoid is not supported!\n",
      "[MAdd]: Hardswish is not supported!\n",
      "[Flops]: Hardswish is not supported!\n",
      "[Memory]: Hardswish is not supported!\n",
      "[MAdd]: Hardswish is not supported!\n",
      "[Flops]: Hardswish is not supported!\n",
      "[Memory]: Hardswish is not supported!\n",
      "[MAdd]: Hardswish is not supported!\n",
      "[Flops]: Hardswish is not supported!\n",
      "[Memory]: Hardswish is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: Flatten is not supported!\n",
      "[Flops]: Flatten is not supported!\n",
      "[Memory]: Flatten is not supported!\n",
      "[MAdd]: Flatten is not supported!\n",
      "[Flops]: Flatten is not supported!\n",
      "[Memory]: Flatten is not supported!\n",
      "[MAdd]: Flatten is not supported!\n",
      "[Flops]: Flatten is not supported!\n",
      "[Memory]: Flatten is not supported!\n",
      "[MAdd]: Hardsigmoid is not supported!\n",
      "[Flops]: Hardsigmoid is not supported!\n",
      "[Memory]: Hardsigmoid is not supported!\n",
      "[MAdd]: Hardsigmoid is not supported!\n",
      "[Flops]: Hardsigmoid is not supported!\n",
      "[Memory]: Hardsigmoid is not supported!\n",
      "[MAdd]: Hardsigmoid is not supported!\n",
      "[Flops]: Hardsigmoid is not supported!\n",
      "[Memory]: Hardsigmoid is not supported!\n",
      "[MAdd]: Hardswish is not supported!\n",
      "[Flops]: Hardswish is not supported!\n",
      "[Memory]: Hardswish is not supported!\n",
      "[MAdd]: Hardswish is not supported!\n",
      "[Flops]: Hardswish is not supported!\n",
      "[Memory]: Hardswish is not supported!\n",
      "[MAdd]: Hardswish is not supported!\n",
      "[Flops]: Hardswish is not supported!\n",
      "[Memory]: Hardswish is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: Flatten is not supported!\n",
      "[Flops]: Flatten is not supported!\n",
      "[Memory]: Flatten is not supported!\n",
      "[MAdd]: Flatten is not supported!\n",
      "[Flops]: Flatten is not supported!\n",
      "[Memory]: Flatten is not supported!\n",
      "[MAdd]: Flatten is not supported!\n",
      "[Flops]: Flatten is not supported!\n",
      "[Memory]: Flatten is not supported!\n",
      "[MAdd]: Hardsigmoid is not supported!\n",
      "[Flops]: Hardsigmoid is not supported!\n",
      "[Memory]: Hardsigmoid is not supported!\n",
      "[MAdd]: Hardsigmoid is not supported!\n",
      "[Flops]: Hardsigmoid is not supported!\n",
      "[Memory]: Hardsigmoid is not supported!\n",
      "[MAdd]: Hardsigmoid is not supported!\n",
      "[Flops]: Hardsigmoid is not supported!\n",
      "[Memory]: Hardsigmoid is not supported!\n",
      "[MAdd]: Hardswish is not supported!\n",
      "[Flops]: Hardswish is not supported!\n",
      "[Memory]: Hardswish is not supported!\n",
      "[MAdd]: Hardswish is not supported!\n",
      "[Flops]: Hardswish is not supported!\n",
      "[Memory]: Hardswish is not supported!\n",
      "[MAdd]: Hardswish is not supported!\n",
      "[Flops]: Hardswish is not supported!\n",
      "[Memory]: Hardswish is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: Flatten is not supported!\n",
      "[Flops]: Flatten is not supported!\n",
      "[Memory]: Flatten is not supported!\n",
      "[MAdd]: Flatten is not supported!\n",
      "[Flops]: Flatten is not supported!\n",
      "[Memory]: Flatten is not supported!\n",
      "[MAdd]: Flatten is not supported!\n",
      "[Flops]: Flatten is not supported!\n",
      "[Memory]: Flatten is not supported!\n",
      "[MAdd]: Hardsigmoid is not supported!\n",
      "[Flops]: Hardsigmoid is not supported!\n",
      "[Memory]: Hardsigmoid is not supported!\n",
      "[MAdd]: Hardsigmoid is not supported!\n",
      "[Flops]: Hardsigmoid is not supported!\n",
      "[Memory]: Hardsigmoid is not supported!\n",
      "[MAdd]: Hardsigmoid is not supported!\n",
      "[Flops]: Hardsigmoid is not supported!\n",
      "[Memory]: Hardsigmoid is not supported!\n",
      "[MAdd]: Hardswish is not supported!\n",
      "[Flops]: Hardswish is not supported!\n",
      "[Memory]: Hardswish is not supported!\n",
      "[MAdd]: Hardswish is not supported!\n",
      "[Flops]: Hardswish is not supported!\n",
      "[Memory]: Hardswish is not supported!\n",
      "[MAdd]: Hardswish is not supported!\n",
      "[Flops]: Hardswish is not supported!\n",
      "[Memory]: Hardswish is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: Flatten is not supported!\n",
      "[Flops]: Flatten is not supported!\n",
      "[Memory]: Flatten is not supported!\n",
      "[MAdd]: Flatten is not supported!\n",
      "[Flops]: Flatten is not supported!\n",
      "[Memory]: Flatten is not supported!\n",
      "[MAdd]: Flatten is not supported!\n",
      "[Flops]: Flatten is not supported!\n",
      "[Memory]: Flatten is not supported!\n",
      "[MAdd]: Hardsigmoid is not supported!\n",
      "[Flops]: Hardsigmoid is not supported!\n",
      "[Memory]: Hardsigmoid is not supported!\n",
      "[MAdd]: Hardsigmoid is not supported!\n",
      "[Flops]: Hardsigmoid is not supported!\n",
      "[Memory]: Hardsigmoid is not supported!\n",
      "[MAdd]: Hardsigmoid is not supported!\n",
      "[Flops]: Hardsigmoid is not supported!\n",
      "[Memory]: Hardsigmoid is not supported!\n",
      "[MAdd]: Hardswish is not supported!\n",
      "[Flops]: Hardswish is not supported!\n",
      "[Memory]: Hardswish is not supported!\n",
      "[MAdd]: Hardswish is not supported!\n",
      "[Flops]: Hardswish is not supported!\n",
      "[Memory]: Hardswish is not supported!\n",
      "[MAdd]: Hardswish is not supported!\n",
      "[Flops]: Hardswish is not supported!\n",
      "[Memory]: Hardswish is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: Flatten is not supported!\n",
      "[Flops]: Flatten is not supported!\n",
      "[Memory]: Flatten is not supported!\n",
      "[MAdd]: Flatten is not supported!\n",
      "[Flops]: Flatten is not supported!\n",
      "[Memory]: Flatten is not supported!\n",
      "[MAdd]: Flatten is not supported!\n",
      "[Flops]: Flatten is not supported!\n",
      "[Memory]: Flatten is not supported!\n",
      "[MAdd]: Hardsigmoid is not supported!\n",
      "[Flops]: Hardsigmoid is not supported!\n",
      "[Memory]: Hardsigmoid is not supported!\n",
      "[MAdd]: Hardsigmoid is not supported!\n",
      "[Flops]: Hardsigmoid is not supported!\n",
      "[Memory]: Hardsigmoid is not supported!\n",
      "[MAdd]: Hardsigmoid is not supported!\n",
      "[Flops]: Hardsigmoid is not supported!\n",
      "[Memory]: Hardsigmoid is not supported!\n",
      "[MAdd]: Hardswish is not supported!\n",
      "[Flops]: Hardswish is not supported!\n",
      "[Memory]: Hardswish is not supported!\n",
      "[MAdd]: Hardswish is not supported!\n",
      "[Flops]: Hardswish is not supported!\n",
      "[Memory]: Hardswish is not supported!\n",
      "[MAdd]: Hardswish is not supported!\n",
      "[Flops]: Hardswish is not supported!\n",
      "[Memory]: Hardswish is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: AdaptiveAvgPool2d is not supported!\n",
      "[Flops]: AdaptiveAvgPool2d is not supported!\n",
      "[Memory]: AdaptiveAvgPool2d is not supported!\n",
      "[MAdd]: Flatten is not supported!\n",
      "[Flops]: Flatten is not supported!\n",
      "[Memory]: Flatten is not supported!\n",
      "[MAdd]: Flatten is not supported!\n",
      "[Flops]: Flatten is not supported!\n",
      "[Memory]: Flatten is not supported!\n",
      "[MAdd]: Flatten is not supported!\n",
      "[Flops]: Flatten is not supported!\n",
      "[Memory]: Flatten is not supported!\n",
      "[MAdd]: Dropout is not supported!\n",
      "[Flops]: Dropout is not supported!\n",
      "[Memory]: Dropout is not supported!\n",
      "[MAdd]: Dropout is not supported!\n",
      "[Flops]: Dropout is not supported!\n",
      "[Memory]: Dropout is not supported!\n",
      "[MAdd]: Dropout is not supported!\n",
      "[Flops]: Dropout is not supported!\n",
      "[Memory]: Dropout is not supported!\n",
      "                               module name  input shape output shape     params memory(MB)           MAdd         Flops  MemRead(B)  MemWrite(B) duration[%]   MemR+W(B)\n",
      "0                               features.0    3 224 224   16 112 112      432.0       0.77   10,637,312.0   5,419,008.0    603840.0     802816.0       0.93%   1406656.0\n",
      "1                               features.1   16 112 112   16 112 112       32.0       0.77      802,816.0     401,408.0    802944.0     802816.0       0.35%   1605760.0\n",
      "2                               features.2   16 112 112   16 112 112        0.0       0.77            0.0           0.0         0.0          0.0       0.52%         0.0\n",
      "3                features.3.bottleneck_0_0   16 112 112   16 112 112      256.0       0.77    6,221,824.0   3,211,264.0    803840.0     802816.0       0.49%   1606656.0\n",
      "4                features.3.bottleneck_0_1   16 112 112   16 112 112       32.0       0.77      802,816.0     401,408.0    802944.0     802816.0       0.38%   1605760.0\n",
      "5                features.3.bottleneck_0_2   16 112 112   16 112 112        0.0       0.77      200,704.0     200,704.0    802816.0     802816.0       0.24%   1605632.0\n",
      "6                features.3.bottleneck_1_0   16 112 112   16  56  56      144.0       0.19      852,992.0     451,584.0    803392.0     200704.0       0.56%   1004096.0\n",
      "7                features.3.bottleneck_1_1   16  56  56   16  56  56       32.0       0.19      200,704.0     100,352.0    200832.0     200704.0       0.27%    401536.0\n",
      "8       features.3.squeeze_excite_0.se_0_0   16  56  56   16   1   1        0.0       0.00            0.0           0.0         0.0          0.0       0.37%         0.0\n",
      "9       features.3.squeeze_excite_0.se_0_1   16   1   1           16        0.0       0.00            0.0           0.0         0.0          0.0       0.29%         0.0\n",
      "10      features.3.squeeze_excite_0.se_1_0           16           16      272.0       0.00          496.0         256.0      1152.0         64.0       0.31%      1216.0\n",
      "11      features.3.squeeze_excite_0.se_1_1           16           16        0.0       0.00           16.0          16.0        64.0         64.0       0.17%       128.0\n",
      "12      features.3.squeeze_excite_0.se_2_0           16           16      272.0       0.00          496.0         256.0      1152.0         64.0       0.22%      1216.0\n",
      "13      features.3.squeeze_excite_0.se_2_1           16           16        0.0       0.00            0.0           0.0         0.0          0.0       0.30%         0.0\n",
      "14           features.3.bottleneck_final_0   16  56  56   16  56  56      256.0       0.19    1,555,456.0     802,816.0    201728.0     200704.0       0.36%    402432.0\n",
      "15           features.3.bottleneck_final_1   16  56  56   16  56  56       32.0       0.19      200,704.0     100,352.0    200832.0     200704.0       0.31%    401536.0\n",
      "16           features.3.bottleneck_final_2   16 112 112   16  56  56      256.0       0.19    1,555,456.0     802,816.0    803840.0     200704.0       0.57%   1004544.0\n",
      "17               features.4.bottleneck_0_0   16  56  56   72  56  56     1152.0       0.86    6,999,552.0   3,612,672.0    205312.0     903168.0       0.37%   1108480.0\n",
      "18               features.4.bottleneck_0_1   72  56  56   72  56  56      144.0       0.86      903,168.0     451,584.0    903744.0     903168.0       0.35%   1806912.0\n",
      "19               features.4.bottleneck_0_2   72  56  56   72  56  56        0.0       0.86      225,792.0     225,792.0    903168.0     903168.0       0.24%   1806336.0\n",
      "20               features.4.bottleneck_1_0   72  56  56   72  28  28      648.0       0.22      959,616.0     508,032.0    905760.0     225792.0       2.87%   1131552.0\n",
      "21               features.4.bottleneck_1_1   72  28  28   72  28  28      144.0       0.22      225,792.0     112,896.0    226368.0     225792.0       0.29%    452160.0\n",
      "22             features.4.squeeze_excite_0   72  28  28   72  28  28        0.0       0.22            0.0           0.0         0.0          0.0       0.31%         0.0\n",
      "23           features.4.bottleneck_final_0   72  28  28   24  28  28     1728.0       0.07    2,690,688.0   1,354,752.0    232704.0      75264.0       0.31%    307968.0\n",
      "24           features.4.bottleneck_final_1   24  28  28   24  28  28       48.0       0.07       75,264.0      37,632.0     75456.0      75264.0       0.26%    150720.0\n",
      "25           features.4.bottleneck_final_2   16  56  56   24  28  28      384.0       0.07      583,296.0     301,056.0    202240.0      75264.0       0.41%    277504.0\n",
      "26               features.5.bottleneck_0_0   24  28  28   88  28  28     2112.0       0.26    3,242,624.0   1,655,808.0     83712.0     275968.0       0.35%    359680.0\n",
      "27               features.5.bottleneck_0_1   88  28  28   88  28  28      176.0       0.26      275,968.0     137,984.0    276672.0     275968.0       0.42%    552640.0\n",
      "28               features.5.bottleneck_0_2   88  28  28   88  28  28        0.0       0.26       68,992.0      68,992.0    275968.0     275968.0       0.29%    551936.0\n",
      "29               features.5.bottleneck_1_0   88  28  28   88  28  28      792.0       0.26    1,172,864.0     620,928.0    279136.0     275968.0       0.62%    555104.0\n",
      "30               features.5.bottleneck_1_1   88  28  28   88  28  28      176.0       0.26      275,968.0     137,984.0    276672.0     275968.0       0.28%    552640.0\n",
      "31             features.5.squeeze_excite_0   88  28  28   88  28  28        0.0       0.26            0.0           0.0         0.0          0.0       0.31%         0.0\n",
      "32           features.5.bottleneck_final_0   88  28  28   24  28  28     2112.0       0.07    3,292,800.0   1,655,808.0    284416.0      75264.0       0.41%    359680.0\n",
      "33           features.5.bottleneck_final_1   24  28  28   24  28  28       48.0       0.07       75,264.0      37,632.0     75456.0      75264.0       0.33%    150720.0\n",
      "34           features.5.bottleneck_final_2   24  28  28   24  28  28      576.0       0.07      884,352.0     451,584.0     77568.0      75264.0       0.40%    152832.0\n",
      "35               features.6.bottleneck_0_0   24  28  28   96  28  28     2304.0       0.29    3,537,408.0   1,806,336.0     84480.0     301056.0       0.38%    385536.0\n",
      "36               features.6.bottleneck_0_1   96  28  28   96  28  28      192.0       0.29      301,056.0     150,528.0    301824.0     301056.0       0.33%    602880.0\n",
      "37               features.6.bottleneck_0_2   96  28  28   96  28  28        0.0       0.29            0.0           0.0         0.0          0.0       0.44%         0.0\n",
      "38               features.6.bottleneck_1_0   96  28  28   96  14  14     2400.0       0.07      921,984.0     470,400.0    310656.0      75264.0       4.18%    385920.0\n",
      "39               features.6.bottleneck_1_1   96  14  14   96  14  14      192.0       0.07       75,264.0      37,632.0     76032.0      75264.0       0.50%    151296.0\n",
      "40      features.6.squeeze_excite_0.se_0_0   96  14  14   96   1   1        0.0       0.00            0.0           0.0         0.0          0.0       0.58%         0.0\n",
      "41      features.6.squeeze_excite_0.se_0_1   96   1   1           96        0.0       0.00            0.0           0.0         0.0          0.0       0.37%         0.0\n",
      "42      features.6.squeeze_excite_0.se_1_0           96           96     9312.0       0.00       18,336.0       9,216.0     37632.0        384.0       0.29%     38016.0\n",
      "43      features.6.squeeze_excite_0.se_1_1           96           96        0.0       0.00           96.0          96.0       384.0        384.0       0.18%       768.0\n",
      "44      features.6.squeeze_excite_0.se_2_0           96           96     9312.0       0.00       18,336.0       9,216.0     37632.0        384.0       0.23%     38016.0\n",
      "45      features.6.squeeze_excite_0.se_2_1           96           96        0.0       0.00            0.0           0.0         0.0          0.0       0.30%         0.0\n",
      "46           features.6.bottleneck_final_0   96  14  14   40  14  14     3840.0       0.03    1,497,440.0     752,640.0     90624.0      31360.0       0.32%    121984.0\n",
      "47           features.6.bottleneck_final_1   40  14  14   40  14  14       80.0       0.03       31,360.0      15,680.0     31680.0      31360.0       0.29%     63040.0\n",
      "48           features.6.bottleneck_final_2   24  28  28   40  14  14      960.0       0.03      368,480.0     188,160.0     79104.0      31360.0       0.29%    110464.0\n",
      "49               features.7.bottleneck_0_0   40  14  14  240  14  14     9600.0       0.18    3,716,160.0   1,881,600.0     69760.0     188160.0       0.34%    257920.0\n",
      "50               features.7.bottleneck_0_1  240  14  14  240  14  14      480.0       0.18      188,160.0      94,080.0    190080.0     188160.0       0.30%    378240.0\n",
      "51               features.7.bottleneck_0_2  240  14  14  240  14  14        0.0       0.18            0.0           0.0         0.0          0.0       0.38%         0.0\n",
      "52               features.7.bottleneck_1_0  240  14  14  240  14  14     6000.0       0.18    2,304,960.0   1,176,000.0    212160.0     188160.0       5.86%    400320.0\n",
      "53               features.7.bottleneck_1_1  240  14  14  240  14  14      480.0       0.18      188,160.0      94,080.0    190080.0     188160.0       0.34%    378240.0\n",
      "54      features.7.squeeze_excite_0.se_0_0  240  14  14  240   1   1        0.0       0.00            0.0           0.0         0.0          0.0       0.38%         0.0\n",
      "55      features.7.squeeze_excite_0.se_0_1  240   1   1          240        0.0       0.00            0.0           0.0         0.0          0.0       0.28%         0.0\n",
      "56      features.7.squeeze_excite_0.se_1_0          240          240    57840.0       0.00      114,960.0      57,600.0    232320.0        960.0       0.28%    233280.0\n",
      "57      features.7.squeeze_excite_0.se_1_1          240          240        0.0       0.00          240.0         240.0       960.0        960.0       0.17%      1920.0\n",
      "58      features.7.squeeze_excite_0.se_2_0          240          240    57840.0       0.00      114,960.0      57,600.0    232320.0        960.0       0.24%    233280.0\n",
      "59      features.7.squeeze_excite_0.se_2_1          240          240        0.0       0.00            0.0           0.0         0.0          0.0       0.30%         0.0\n",
      "60           features.7.bottleneck_final_0  240  14  14   40  14  14     9600.0       0.03    3,755,360.0   1,881,600.0    226560.0      31360.0       0.33%    257920.0\n",
      "61           features.7.bottleneck_final_1   40  14  14   40  14  14       80.0       0.03       31,360.0      15,680.0     31680.0      31360.0       0.27%     63040.0\n",
      "62           features.7.bottleneck_final_2   40  14  14   40  14  14     1600.0       0.03      619,360.0     313,600.0     37760.0      31360.0       0.27%     69120.0\n",
      "63               features.8.bottleneck_0_0   40  14  14  240  14  14     9600.0       0.18    3,716,160.0   1,881,600.0     69760.0     188160.0       0.30%    257920.0\n",
      "64               features.8.bottleneck_0_1  240  14  14  240  14  14      480.0       0.18      188,160.0      94,080.0    190080.0     188160.0       0.28%    378240.0\n",
      "65               features.8.bottleneck_0_2  240  14  14  240  14  14        0.0       0.18            0.0           0.0         0.0          0.0       0.34%         0.0\n",
      "66               features.8.bottleneck_1_0  240  14  14  240  14  14     6000.0       0.18    2,304,960.0   1,176,000.0    212160.0     188160.0       5.86%    400320.0\n",
      "67               features.8.bottleneck_1_1  240  14  14  240  14  14      480.0       0.18      188,160.0      94,080.0    190080.0     188160.0       0.37%    378240.0\n",
      "68      features.8.squeeze_excite_0.se_0_0  240  14  14  240   1   1        0.0       0.00            0.0           0.0         0.0          0.0       0.41%         0.0\n",
      "69      features.8.squeeze_excite_0.se_0_1  240   1   1          240        0.0       0.00            0.0           0.0         0.0          0.0       0.29%         0.0\n",
      "70      features.8.squeeze_excite_0.se_1_0          240          240    57840.0       0.00      114,960.0      57,600.0    232320.0        960.0       0.33%    233280.0\n",
      "71      features.8.squeeze_excite_0.se_1_1          240          240        0.0       0.00          240.0         240.0       960.0        960.0       0.19%      1920.0\n",
      "72      features.8.squeeze_excite_0.se_2_0          240          240    57840.0       0.00      114,960.0      57,600.0    232320.0        960.0       0.27%    233280.0\n",
      "73      features.8.squeeze_excite_0.se_2_1          240          240        0.0       0.00            0.0           0.0         0.0          0.0       0.31%         0.0\n",
      "74           features.8.bottleneck_final_0  240  14  14   40  14  14     9600.0       0.03    3,755,360.0   1,881,600.0    226560.0      31360.0       0.36%    257920.0\n",
      "75           features.8.bottleneck_final_1   40  14  14   40  14  14       80.0       0.03       31,360.0      15,680.0     31680.0      31360.0       0.28%     63040.0\n",
      "76           features.8.bottleneck_final_2   40  14  14   40  14  14     1600.0       0.03      619,360.0     313,600.0     37760.0      31360.0       0.27%     69120.0\n",
      "77               features.9.bottleneck_0_0   40  14  14  120  14  14     4800.0       0.09    1,858,080.0     940,800.0     50560.0      94080.0       0.31%    144640.0\n",
      "78               features.9.bottleneck_0_1  120  14  14  120  14  14      240.0       0.09       94,080.0      47,040.0     95040.0      94080.0       0.27%    189120.0\n",
      "79               features.9.bottleneck_0_2  120  14  14  120  14  14        0.0       0.09            0.0           0.0         0.0          0.0       0.33%         0.0\n",
      "80               features.9.bottleneck_1_0  120  14  14  120  14  14     3000.0       0.09    1,152,480.0     588,000.0    106080.0      94080.0       3.20%    200160.0\n",
      "81               features.9.bottleneck_1_1  120  14  14  120  14  14      240.0       0.09       94,080.0      47,040.0     95040.0      94080.0       0.29%    189120.0\n",
      "82      features.9.squeeze_excite_0.se_0_0  120  14  14  120   1   1        0.0       0.00            0.0           0.0         0.0          0.0       0.36%         0.0\n",
      "83      features.9.squeeze_excite_0.se_0_1  120   1   1          120        0.0       0.00            0.0           0.0         0.0          0.0       0.29%         0.0\n",
      "84      features.9.squeeze_excite_0.se_1_0          120          120    14520.0       0.00       28,680.0      14,400.0     58560.0        480.0       0.26%     59040.0\n",
      "85      features.9.squeeze_excite_0.se_1_1          120          120        0.0       0.00          120.0         120.0       480.0        480.0       0.17%       960.0\n",
      "86      features.9.squeeze_excite_0.se_2_0          120          120    14520.0       0.00       28,680.0      14,400.0     58560.0        480.0       0.24%     59040.0\n",
      "87      features.9.squeeze_excite_0.se_2_1          120          120        0.0       0.00            0.0           0.0         0.0          0.0       0.30%         0.0\n",
      "88           features.9.bottleneck_final_0  120  14  14   48  14  14     5760.0       0.04    2,248,512.0   1,128,960.0    117120.0      37632.0       0.31%    154752.0\n",
      "89           features.9.bottleneck_final_1   48  14  14   48  14  14       96.0       0.04       37,632.0      18,816.0     38016.0      37632.0       0.27%     75648.0\n",
      "90           features.9.bottleneck_final_2   40  14  14   48  14  14     1920.0       0.04      743,232.0     376,320.0     39040.0      37632.0       0.25%     76672.0\n",
      "91              features.10.bottleneck_0_0   48  14  14  144  14  14     6912.0       0.11    2,681,280.0   1,354,752.0     65280.0     112896.0       0.28%    178176.0\n",
      "92              features.10.bottleneck_0_1  144  14  14  144  14  14      288.0       0.11      112,896.0      56,448.0    114048.0     112896.0       0.26%    226944.0\n",
      "93              features.10.bottleneck_0_2  144  14  14  144  14  14        0.0       0.11            0.0           0.0         0.0          0.0       0.32%         0.0\n",
      "94              features.10.bottleneck_1_0  144  14  14  144  14  14     3600.0       0.11    1,382,976.0     705,600.0    127296.0     112896.0       3.46%    240192.0\n",
      "95              features.10.bottleneck_1_1  144  14  14  144  14  14      288.0       0.11      112,896.0      56,448.0    114048.0     112896.0       0.28%    226944.0\n",
      "96     features.10.squeeze_excite_0.se_0_0  144  14  14  144   1   1        0.0       0.00            0.0           0.0         0.0          0.0       0.33%         0.0\n",
      "97     features.10.squeeze_excite_0.se_0_1  144   1   1          144        0.0       0.00            0.0           0.0         0.0          0.0       0.28%         0.0\n",
      "98     features.10.squeeze_excite_0.se_1_0          144          144    20880.0       0.00       41,328.0      20,736.0     84096.0        576.0       0.25%     84672.0\n",
      "99     features.10.squeeze_excite_0.se_1_1          144          144        0.0       0.00          144.0         144.0       576.0        576.0       0.17%      1152.0\n",
      "100    features.10.squeeze_excite_0.se_2_0          144          144    20880.0       0.00       41,328.0      20,736.0     84096.0        576.0       0.23%     84672.0\n",
      "101    features.10.squeeze_excite_0.se_2_1          144          144        0.0       0.00            0.0           0.0         0.0          0.0       0.28%         0.0\n",
      "102         features.10.bottleneck_final_0  144  14  14   48  14  14     6912.0       0.04    2,700,096.0   1,354,752.0    140544.0      37632.0       0.30%    178176.0\n",
      "103         features.10.bottleneck_final_1   48  14  14   48  14  14       96.0       0.04       37,632.0      18,816.0     38016.0      37632.0       0.25%     75648.0\n",
      "104         features.10.bottleneck_final_2   48  14  14   48  14  14     2304.0       0.04      893,760.0     451,584.0     46848.0      37632.0       0.25%     84480.0\n",
      "105             features.11.bottleneck_0_0   48  14  14  288  14  14    13824.0       0.22    5,362,560.0   2,709,504.0     92928.0     225792.0       0.31%    318720.0\n",
      "106             features.11.bottleneck_0_1  288  14  14  288  14  14      576.0       0.22      225,792.0     112,896.0    228096.0     225792.0       0.27%    453888.0\n",
      "107             features.11.bottleneck_0_2  288  14  14  288  14  14        0.0       0.22            0.0           0.0         0.0          0.0       0.34%         0.0\n",
      "108             features.11.bottleneck_1_0  288  14  14  288   7   7     7200.0       0.05      691,488.0     352,800.0    254592.0      56448.0       6.07%    311040.0\n",
      "109             features.11.bottleneck_1_1  288   7   7  288   7   7      576.0       0.05       56,448.0      28,224.0     58752.0      56448.0       0.26%    115200.0\n",
      "110    features.11.squeeze_excite_0.se_0_0  288   7   7  288   1   1        0.0       0.00            0.0           0.0         0.0          0.0       0.32%         0.0\n",
      "111    features.11.squeeze_excite_0.se_0_1  288   1   1          288        0.0       0.00            0.0           0.0         0.0          0.0       0.28%         0.0\n",
      "112    features.11.squeeze_excite_0.se_1_0          288          288    83232.0       0.00      165,600.0      82,944.0    334080.0       1152.0       0.28%    335232.0\n",
      "113    features.11.squeeze_excite_0.se_1_1          288          288        0.0       0.00          288.0         288.0      1152.0       1152.0       0.17%      2304.0\n",
      "114    features.11.squeeze_excite_0.se_2_0          288          288    83232.0       0.00      165,600.0      82,944.0    334080.0       1152.0       0.32%    335232.0\n",
      "115    features.11.squeeze_excite_0.se_2_1          288          288        0.0       0.00            0.0           0.0         0.0          0.0       0.30%         0.0\n",
      "116         features.11.bottleneck_final_0  288   7   7   96   7   7    27648.0       0.02    2,704,800.0   1,354,752.0    167040.0      18816.0       0.31%    185856.0\n",
      "117         features.11.bottleneck_final_1   96   7   7   96   7   7      192.0       0.02       18,816.0       9,408.0     19584.0      18816.0       0.25%     38400.0\n",
      "118         features.11.bottleneck_final_2   48  14  14   96   7   7     4608.0       0.02      446,880.0     225,792.0     56064.0      18816.0       0.26%     74880.0\n",
      "119             features.12.bottleneck_0_0   96   7   7  576   7   7    55296.0       0.11    5,390,784.0   2,709,504.0    240000.0     112896.0       0.33%    352896.0\n",
      "120             features.12.bottleneck_0_1  576   7   7  576   7   7     1152.0       0.11      112,896.0      56,448.0    117504.0     112896.0       0.27%    230400.0\n",
      "121             features.12.bottleneck_0_2  576   7   7  576   7   7        0.0       0.11            0.0           0.0         0.0          0.0       0.32%         0.0\n",
      "122             features.12.bottleneck_1_0  576   7   7  576   7   7    14400.0       0.11    1,382,976.0     705,600.0    170496.0     112896.0      10.84%    283392.0\n",
      "123             features.12.bottleneck_1_1  576   7   7  576   7   7     1152.0       0.11      112,896.0      56,448.0    117504.0     112896.0       0.28%    230400.0\n",
      "124    features.12.squeeze_excite_0.se_0_0  576   7   7  576   1   1        0.0       0.00            0.0           0.0         0.0          0.0       0.32%         0.0\n",
      "125    features.12.squeeze_excite_0.se_0_1  576   1   1          576        0.0       0.00            0.0           0.0         0.0          0.0       0.28%         0.0\n",
      "126    features.12.squeeze_excite_0.se_1_0          576          576   332352.0       0.00      662,976.0     331,776.0   1331712.0       2304.0       0.37%   1334016.0\n",
      "127    features.12.squeeze_excite_0.se_1_1          576          576        0.0       0.00          576.0         576.0      2304.0       2304.0       0.17%      4608.0\n",
      "128    features.12.squeeze_excite_0.se_2_0          576          576   332352.0       0.00      662,976.0     331,776.0   1331712.0       2304.0       0.33%   1334016.0\n",
      "129    features.12.squeeze_excite_0.se_2_1          576          576        0.0       0.00            0.0           0.0         0.0          0.0       0.29%         0.0\n",
      "130         features.12.bottleneck_final_0  576   7   7   96   7   7    55296.0       0.02    5,414,304.0   2,709,504.0    334080.0      18816.0       0.36%    352896.0\n",
      "131         features.12.bottleneck_final_1   96   7   7   96   7   7      192.0       0.02       18,816.0       9,408.0     19584.0      18816.0       0.26%     38400.0\n",
      "132         features.12.bottleneck_final_2   96   7   7   96   7   7     9216.0       0.02      898,464.0     451,584.0     55680.0      18816.0       0.26%     74496.0\n",
      "133             features.13.bottleneck_0_0   96   7   7  576   7   7    55296.0       0.11    5,390,784.0   2,709,504.0    240000.0     112896.0       0.33%    352896.0\n",
      "134             features.13.bottleneck_0_1  576   7   7  576   7   7     1152.0       0.11      112,896.0      56,448.0    117504.0     112896.0       0.26%    230400.0\n",
      "135             features.13.bottleneck_0_2  576   7   7  576   7   7        0.0       0.11            0.0           0.0         0.0          0.0       0.32%         0.0\n",
      "136             features.13.bottleneck_1_0  576   7   7  576   7   7    14400.0       0.11    1,382,976.0     705,600.0    170496.0     112896.0      10.99%    283392.0\n",
      "137             features.13.bottleneck_1_1  576   7   7  576   7   7     1152.0       0.11      112,896.0      56,448.0    117504.0     112896.0       0.27%    230400.0\n",
      "138    features.13.squeeze_excite_0.se_0_0  576   7   7  576   1   1        0.0       0.00            0.0           0.0         0.0          0.0       0.32%         0.0\n",
      "139    features.13.squeeze_excite_0.se_0_1  576   1   1          576        0.0       0.00            0.0           0.0         0.0          0.0       0.29%         0.0\n",
      "140    features.13.squeeze_excite_0.se_1_0          576          576   332352.0       0.00      662,976.0     331,776.0   1331712.0       2304.0       0.59%   1334016.0\n",
      "141    features.13.squeeze_excite_0.se_1_1          576          576        0.0       0.00          576.0         576.0      2304.0       2304.0       0.17%      4608.0\n",
      "142    features.13.squeeze_excite_0.se_2_0          576          576   332352.0       0.00      662,976.0     331,776.0   1331712.0       2304.0       0.33%   1334016.0\n",
      "143    features.13.squeeze_excite_0.se_2_1          576          576        0.0       0.00            0.0           0.0         0.0          0.0       0.30%         0.0\n",
      "144         features.13.bottleneck_final_0  576   7   7   96   7   7    55296.0       0.02    5,414,304.0   2,709,504.0    334080.0      18816.0       0.35%    352896.0\n",
      "145         features.13.bottleneck_final_1   96   7   7   96   7   7      192.0       0.02       18,816.0       9,408.0     19584.0      18816.0       0.25%     38400.0\n",
      "146         features.13.bottleneck_final_2   96   7   7   96   7   7     9216.0       0.02      898,464.0     451,584.0     55680.0      18816.0       0.26%     74496.0\n",
      "147                            features.14   96   7   7  576   7   7    55296.0       0.11    5,390,784.0   2,709,504.0    240000.0     112896.0       0.33%    352896.0\n",
      "148                            features.15  576   7   7  576   7   7        0.0       0.11            0.0           0.0         0.0          0.0       0.34%         0.0\n",
      "149                            features.16  576   7   7  576   7   7     1152.0       0.11      112,896.0      56,448.0    117504.0     112896.0       0.33%    230400.0\n",
      "150                          classifiers.0  576   7   7  576   1   1        0.0       0.00            0.0           0.0         0.0          0.0       0.54%         0.0\n",
      "151                          classifiers.1  576   1   1          576        0.0       0.00            0.0           0.0         0.0          0.0       0.27%         0.0\n",
      "152                          classifiers.2          576         1024   590848.0       0.00    1,178,624.0     589,824.0   2365696.0       4096.0       0.45%   2369792.0\n",
      "153                          classifiers.3         1024         1024        0.0       0.00            0.0           0.0         0.0          0.0       0.28%         0.0\n",
      "154                          classifiers.4         1024         1000  1025000.0       0.00    2,047,000.0   1,024,000.0   4104096.0       4000.0       0.48%   4108096.0\n",
      "total                                                                 3931344.0      17.44  135,993,728.0  69,127,928.0   4104096.0       4000.0     100.00%  48001696.0\n",
      "========================================================================================================================================================================\n",
      "Total params: 3,931,344\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total memory: 17.44MB\n",
      "Total MAdd: 135.99MMAdd\n",
      "Total Flops: 69.13MFlops\n",
      "Total MemR+W: 45.78MB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torchstat\n",
    "torchstat.stat(model.cpu(), (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6037fcbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.Image.Image'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-4097df8cf0c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mtest_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mnp_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mnp_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.Image.Image'>"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageDraw\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "inline_transform = transforms.Normalize(\n",
    "    mean=[0.4547857, 0.4349471, 0.40525291],\n",
    "    std=[0.12003352, 0.12323549, 0.1392444]\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_dataloader = torch.utils.data.DataLoader(datasets, batch_size=1, shuffle=True, num_workers=0, pin_memory=True, drop_last=False)\n",
    "    for i, (image, label) in enumerate(test_dataloader):\n",
    "        np_image = (np.transpose(image.squeeze().numpy(), (2, 1, 0)) * 255).astype(np.uint8)\n",
    "        np_label = label.numpy()\n",
    "        pil_image = Image.fromarray(np_image)\n",
    "        \n",
    "        output = model(inline_transform(image).cuda())\n",
    "        cpu_output = torch.argmax(output).cpu().numpy().squeeze()\n",
    "        \n",
    "        draw = ImageDraw.Draw(pil_image)\n",
    "        draw.text((0, 0), labels.values())[cpu_output.item()], (255,255,255))\n",
    "        plt.imshow(np.asarray(pil_image))\n",
    "        plt.show()\n",
    "\n",
    "        if i > 5:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
